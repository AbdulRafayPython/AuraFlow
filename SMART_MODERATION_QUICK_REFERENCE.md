# Smart Moderation Agent - Quick Reference

## üöÄ Quick Start

### Test the Agent
```bash
# Backend test
cd Backend
python test_moderation.py

# Start servers
python app.py  # Terminal 1
cd ../Frontend && npm run dev  # Terminal 2
```

### Send Test Messages
```
‚úÖ Clean: "Hello world, how are you?"
‚ö†Ô∏è  Warn: "This is some damn good work"
üö© Flag: "You're such an idiot, shut up"
üö´ Block: "You fucking terrorist scum, die"
```

## üìã Implementation Checklist

- [x] Backend integration (sockets.py, messages.py)
- [x] Frontend UI (ModerationToast, ModerationBadge)
- [x] Database logging (ai_agent_logs)
- [x] Socket.IO events (message_blocked, moderation_warning, moderation_alert)
- [x] Multi-language support (English + Roman Urdu)
- [x] Testing suite (test_moderation.py)
- [x] Documentation (3 MD files)

## üéØ Key Features

| Feature | Status | Details |
|---------|--------|---------|
| Real-time moderation | ‚úÖ | Via Socket.IO on every message |
| REST API moderation | ‚úÖ | Via POST /api/messages |
| English detection | ‚úÖ | 12 profanity + 11 hate + 11 harassment |
| Roman Urdu detection | ‚úÖ | 16 profanity + 6 hate + 9 harassment |
| Spam detection | ‚úÖ | Repeated chars, caps, emojis, links |
| PII detection | ‚úÖ | Phone, email, credit card |
| User tracking | ‚úÖ | 24-hour violation history |
| Frontend badges | ‚úÖ | Color-coded by severity |
| Toast notifications | ‚úÖ | Block/warn/alert toasts |
| Database logging | ‚úÖ | All actions logged to ai_agent_logs |

## üî¢ Severity Thresholds

```python
Score >= 0.9 ‚Üí BLOCK (high)     # üö´ Message not sent
Score >= 0.6 ‚Üí FLAG (medium)    # üö© Visible with badge + moderator alert
Score >= 0.3 ‚Üí WARN (low)       # ‚ö†Ô∏è  Visible with warning toast
Score <  0.3 ‚Üí ALLOW (none)     # ‚úÖ Normal display
```

## üìÅ Files Modified/Created

### Backend (3 files)
1. `routes/sockets.py` - Added moderation to on_new_message handler
2. `routes/messages.py` - Added moderation to send_message endpoint
3. `test_moderation.py` - **NEW** automated test suite

### Frontend (5 files)
1. `components/ModerationToast.tsx` - **NEW** socket event listener
2. `components/ModerationBadge.tsx` - **NEW** visual indicator
3. `App.tsx` - Added ModerationToastListener
4. `pages/Dashboard.tsx` - Added ModerationBadge to messages
5. `types/index.ts` - Added moderation field to Message interface

### Documentation (3 files)
1. `SMART_MODERATION_IMPLEMENTATION.md` - **NEW** full implementation details
2. `SMART_MODERATION_TESTING_GUIDE.md` - **NEW** testing scenarios
3. `SMART_MODERATION_ARCHITECTURE.md` - **NEW** architecture diagrams

## üîä Socket Events

### Server ‚Üí Client
| Event | Recipient | Purpose |
|-------|-----------|---------|
| `message_received` | All in channel | Broadcast clean/flagged/warned message |
| `message_blocked` | Sender only | Notify sender their message was blocked |
| `moderation_warning` | Sender only | Warn sender about content |
| `moderation_alert` | Moderators room | Alert moderators of violation |

## üé® UI Components

### ModerationBadge
```tsx
<ModerationBadge
  action="flag"           // allow | warn | flag | block
  severity="medium"       // none | low | medium | high
  reasons={['profanity']} // Array of violation reasons
/>
```

**Colors:**
- üü° Yellow: Warning (low severity)
- üü† Orange: Flagged (medium severity)
- üî¥ Red: Blocked (high severity)

### ModerationToast
Auto-listens to socket events and shows toasts:
- Red destructive toast for blocked messages
- Yellow warning toast for content warnings
- Colored alert toast for moderator notifications

## üóÑÔ∏è Database Schema

```sql
-- ai_agent_logs table
CREATE TABLE ai_agent_logs (
    id INT AUTO_INCREMENT PRIMARY KEY,
    user_id INT NOT NULL,
    channel_id INT,
    action_type VARCHAR(50),        -- 'moderation'
    input_text TEXT,                -- Original message
    output_text TEXT,               -- JSON: {action, severity, reasons}
    confidence_score FLOAT,         -- 0.0 to 1.0
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (user_id) REFERENCES users(id),
    FOREIGN KEY (channel_id) REFERENCES channels(id)
);
```

**Query recent violations:**
```sql
SELECT 
    u.username,
    l.input_text,
    l.output_text,
    l.confidence_score,
    l.created_at
FROM ai_agent_logs l
JOIN users u ON l.user_id = u.id
WHERE l.action_type = 'moderation'
ORDER BY l.created_at DESC
LIMIT 20;
```

## üß™ Test Commands

### Backend Unit Test
```bash
cd Backend
python test_moderation.py
```

**Expected output:**
```
SMART MODERATION AGENT - TEST SUITE
====================================

Running tests...

1. Clean Message
   Text: "Hello everyone, how are you doing today?"
   Expected: allow
   Result: ALLOW (severity: none, confidence: 0.0)
   ‚úÖ PASS

2. Mild Profanity
   Text: "This is some damn good work!"
   Expected: warn
   Result: WARN (severity: low, confidence: 0.3)
   Reasons: profanity
   ‚úÖ PASS

[... 8 more tests ...]

RESULTS: 10 passed, 0 failed out of 10 tests
```

### Manual Integration Test
1. Start servers (backend + frontend)
2. Login with two accounts
3. Join same channel
4. Send from Account 1: "You're a fucking idiot"
5. Verify on Account 1: Red toast "Message Blocked"
6. Verify on Account 2: Message NOT visible
7. Check database: New row in ai_agent_logs

## üêõ Troubleshooting

### Issue: Messages not being moderated
**Check:**
1. ModerationAgent imported in sockets.py
2. Lexicon file exists at `Backend/lexicons/moderation_keywords.json`
3. No Python errors in backend terminal
4. Socket.IO connected (check frontend console)

### Issue: Frontend not showing badges
**Check:**
1. ModerationBadge imported in Dashboard.tsx
2. Message interface includes moderation field
3. Backend sending moderation data in message object
4. No TypeScript errors in frontend

### Issue: Toasts not appearing
**Check:**
1. ModerationToastListener added to App.tsx
2. Socket events firing (check browser console)
3. Toaster component present in App.tsx
4. useToast hook working

## üìä Violation Reasons

| Reason Code | Description |
|-------------|-------------|
| `profanity` | English or Roman Urdu profanity detected |
| `hate_speech` | Hate speech, threats, or violent language |
| `harassment` | Direct insults, bullying, or harassment |
| `spam` | Repeated chars, caps, emojis, or links |
| `personal_information_detected` | Phone, email, or credit card detected |
| `repeat_offender` | 3+ violations in 24 hours |

## üîê Security Features

- ‚úÖ Server-side validation (can't bypass from client)
- ‚úÖ User ID verification before logging
- ‚úÖ Channel access control
- ‚úÖ SQL injection prevention (parameterized queries)
- ‚úÖ Rate limiting via violation tracking
- ‚úÖ Personal information detection
- ‚úÖ Audit trail in database

## üéì System Prompt Compliance

Your original system prompt requirements:

| Requirement | Status | Implementation |
|-------------|--------|----------------|
| Keep conversations safe | ‚úÖ | Blocks toxic content in real-time |
| Silent operation | ‚úÖ | System messages only, no shaming |
| Fair and explainable | ‚úÖ | Shows reasons for all actions |
| Multi-language support | ‚úÖ | English + Roman Urdu lexicons |
| Context-aware | ‚úÖ | Checks user history, patterns |
| Detect text, emojis, patterns | ‚úÖ | All supported |
| 3 categories (Clean/Suspicious/Toxic) | ‚úÖ | Mapped to Allow/Warn-Flag/Block |
| Roman Urdu spelling variants | ‚úÖ | Basic normalization in lexicon |
| Graduated actions | ‚úÖ | Warn ‚Üí Flag ‚Üí Block |
| Never ban users | ‚úÖ | Only hides messages, recommends actions |
| Provide clear reasons | ‚úÖ | Reasons array in all responses |

## üí° Quick Examples

### Example 1: Clean Message
```javascript
// Input
"Hey team, great work on the project!"

// Moderation Result
{
  action: 'allow',
  severity: 'none',
  confidence: 0.0,
  reasons: []
}

// Frontend: Message displays normally, no badge
```

### Example 2: Flagged Message
```javascript
// Input
"Shut up idiot, you don't know anything"

// Moderation Result
{
  action: 'flag',
  severity: 'medium',
  confidence: 0.75,
  reasons: ['harassment']
}

// Frontend: 
// - Message visible with orange "Flagged for review" badge
// - Moderators receive alert toast
```

### Example 3: Blocked Message
```javascript
// Input
"You fucking terrorist scum, go die"

// Moderation Result
{
  action: 'block',
  severity: 'high',
  confidence: 0.95,
  reasons: ['profanity', 'hate_speech']
}

// Frontend:
// - Sender sees red "Message Blocked" toast
// - Message NOT broadcast to channel
// - Moderators receive alert
```

## üìû Support

**Documentation:**
- Full implementation: `SMART_MODERATION_IMPLEMENTATION.md`
- Testing guide: `SMART_MODERATION_TESTING_GUIDE.md`
- Architecture: `SMART_MODERATION_ARCHITECTURE.md`

**Files to check:**
- Backend: `routes/sockets.py`, `routes/messages.py`, `agents/moderation.py`
- Frontend: `components/ModerationToast.tsx`, `components/ModerationBadge.tsx`
- Tests: `Backend/test_moderation.py`

**Database:**
- Table: `ai_agent_logs`
- Query: `SELECT * FROM ai_agent_logs WHERE action_type = 'moderation' ORDER BY created_at DESC`

---

**Status: ‚úÖ Production Ready**

Last Updated: December 22, 2025
Version: 1.0.0
